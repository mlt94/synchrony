This file is just an overview to keep track of all the data-cleaning activites that takes place
OpenFace Outputs and the transcripts.

1: Removing some dyads 
I decide to remove the identifiers from the source dataset, which have only
4 recordings (i.e., no wunder question --> C3IJ, C4OF, I9LB, K8OM).
I also remove the two recordings from N1EL that has "Personal1", leaving 6 for this dyad.
I also remove the two recordings from C8LA that has "Personal", leaving 6 for this dyad.
I remove S5EA as the client and therapist had virtually indistinguiable voices, so the diarization model could not tell them apart.
The source corpus has two files pr. person (A2ER) in the "Bindung" section; we combine these two as the video was interrupted due to internet connection  
This leaves 78 dyads, with 6 recordings each.

2: Align_fps.
The source openface outputs came from recordings with different fps.
the scripts/source_data_clean/align_fps.py script solves this, and takes a --target-fps fps.
Its solved through a simple rolling window mean (pandas.rolling) for smoothing out the features and then 
a linear interpolation onto the new timegrid.

3: Transcripts 
Transcripts are executed using scripts_language/language_pipeline.py. (15-XX october 2025).
The minimum duration of speech turn required for transcription is 1500 ms.
The logic assigns client/therapist label according to the most speaking part.
This is incorrect in a few instances, and is manually inspected with scripts_source_data_clean/consistency_check_therapist_client.py
The label is then swapped and saved inplace when nessesary. 

4: Source-data matching
The script .. outputs a yaml file containing the file matchings between the transcripts and the openface outputs



