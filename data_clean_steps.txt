This file is just an overview to keep track of all the data-cleaning activites that takes place
OpenFace Outputs and the transcripts.

1: Removing some dyads according to unpack_source_openface_outputs.py
and align A2ER according to combine_bindung_recordings_A2ER.py (C:\Users\User\Desktop\martins\synchrony> python .\source\scripts_source_data_clean\combine_bindung_recordings_A2ER.py --root C:\Users\User\Desktop\martins\output_files\Openface_Output_MSB\A2ER)
Then create data model using populate_data_model_yaml.py

2: Align_fps.
The source openface outputs came from recordings with different fps.
the scripts/source_data_clean/align_fps.py script solves this, and takes a --target-fps fps.
Its solved through a simple rolling window mean (pandas.rolling) for smoothing out the features and then 
a linear interpolation onto the new timegrid.

3: Transcripts 
Transcripts are executed using scripts_language/language_pipeline.py. (15-XX october 2025).
The minimum duration of speech turn required for transcription is 1500 ms.
The logic assigns client/therapist label according to the most speaking part.
This is incorrect in a few instances, and is manually inspected with scripts_source_data_clean/consistency_check_therapist_client.py
The label is then swapped and saved inplace when nessesary. 

4: Source-data matching
The script .. outputs a yaml file containing the file matchings between the transcripts and the openface outputs



